{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85832b1-9f31-41e4-b934-cc260e5b3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, glob, os, torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f50013-6513-44fd-8e48-06dd12ec3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'WINDOW_SIZE':500,\n",
    "    'EPOCHS':100,\n",
    "    'LEARNING_RATE':1e-3,\n",
    "    'BATCH_SIZE':128,\n",
    "    'SEED':41,\n",
    "    'FOLD':5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cdbe67-eda2-42ef-bc35-0a2bfd99f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b89389",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob.glob('./train/*.csv')\n",
    "test_paths = pd.read_csv('./test.csv')['data_path'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9509bd54-9333-4ec7-b197-b70d3c1408ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes = {\n",
    "    'Time[s]': {'min': float('inf'), 'max': float('-inf'), 'mean': float('inf'), 'std': float('inf'), \n",
    "                'median': float('inf'), 'sum': float('inf'), 'q1': float('inf'), 'q3': float('inf')},\n",
    "    'Signal A': {'min': float('inf'), 'max': float('-inf'), 'mean': float('inf'), 'std': float('inf'), \n",
    "                 'median': float('inf'), 'sum': float('inf'), 'q1': float('inf'), 'q3': float('inf')},\n",
    "    'Signal B': {'min': float('inf'), 'max': float('-inf'), 'mean': float('inf'), 'std': float('inf'), \n",
    "                 'median': float('inf'), 'sum': float('inf'), 'q1': float('inf'), 'q3': float('inf')},\n",
    "    'Signal C': {'min': float('inf'), 'max': float('-inf'), 'mean': float('inf'), 'std': float('inf'), \n",
    "                 'median': float('inf'), 'sum': float('inf'), 'q1': float('inf'), 'q3': float('inf')},\n",
    "    'Sensor A': {'min': float('inf'), 'max': float('-inf'), 'mean': float('inf'), 'std': float('inf'), \n",
    "                 'median': float('inf'), 'sum': float('inf'), 'q1': float('inf'), 'q3': float('inf')},\n",
    "    'Sensor B': {'min': float('inf'), 'max': float('-inf'), 'mean': float('inf'), 'std': float('inf'), \n",
    "                 'median': float('inf'), 'sum': float('inf'), 'q1': float('inf'), 'q3': float('inf')},\n",
    "    'Sensor C': {'min': float('inf'), 'max': float('-inf'), 'mean': float('inf'), 'std': float('inf'), \n",
    "                 'median': float('inf'), 'sum': float('inf'), 'q1': float('inf'), 'q3': float('inf')},\n",
    "    'Sensor D': {'min': float('inf'), 'max': float('-inf'), 'mean': float('inf'), 'std': float('inf'), \n",
    "                 'median': float('inf'), 'sum': float('inf'), 'q1': float('inf'), 'q3': float('inf')}\n",
    "}\n",
    "\n",
    "for path in train_paths:\n",
    "    data = pd.read_csv(path)\n",
    "    for column in extremes.keys():\n",
    "        extremes[column]['min'] = min(extremes[column]['min'], data[column].min())\n",
    "        extremes[column]['max'] = max(extremes[column]['max'], data[column].max())\n",
    "        extremes[column]['median'] = data[column].median()\n",
    "        extremes[column]['mean'] = data[column].mean()\n",
    "        extremes[column]['sum'] = data[column].sum()\n",
    "        extremes[column]['std'] = data[column].std()\n",
    "        extremes[column]['q1'] = data[column].quantile(0.25)\n",
    "        extremes[column]['q3'] = data[column].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "debff992-a1f4-4ade-b2e9-45b234e44412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(train_paths, window_size=CFG['WINDOW_SIZE'], stride=10):\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    for path in tqdm(train_paths):\n",
    "        driver = str(path.split('/')[-1].split('.')[0].split('_')[1][0])\n",
    "        data = pd.read_csv(path)\n",
    "        data['driver'] = 0 if driver == 'A' else 1\n",
    "        label = float(path.split('/')[-1].split('.')[0].split('_')[0][:-2])\n",
    "        label = label / 902.\n",
    "        for i in range(0, len(data) - window_size + 1, stride):\n",
    "            window_data = data.iloc[i:i + window_size].copy()\n",
    "            for i, (column, stats) in enumerate(extremes.items()):\n",
    "                if column in ['Signal A', 'Signal B', 'Signal C']:\n",
    "                    window_data[column] = (window_data[column] - stats['min']) / (stats['max'] - stats['min'])\n",
    "                elif column == 'Time[s]':\n",
    "                    window_data[column] = (window_data[column] - stats['mean']) / stats['std']\n",
    "                elif column in ['Sensor A', 'Sensor B', 'Sensor C', 'Sensor D']:\n",
    "                    window_data[column] = (window_data[column] - stats['median']) / (stats['q3'] - stats['q1'])\n",
    "            sequences.append(window_data.to_numpy())\n",
    "            sequence_labels.append(label)\n",
    "    return np.array(sequences), np.array(sequence_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08b43fb-bcdf-466f-8501-3b23f178986a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d792ca749db94c37a4b926395caf2dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_window_data, train_labels = make_train_data(train_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "037cad2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18453, 500, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_window_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf39b0f-64f4-4126-9a3d-da5de9f624d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict_data(test_paths, window_size=CFG['WINDOW_SIZE']):\n",
    "    sequences = []\n",
    "    for path in tqdm(test_paths):\n",
    "        driver = str(path.split('/')[-1].split('.')[0].split('_')[1][0])\n",
    "        data = pd.read_csv(path)\n",
    "        data['driver'] = 0 if driver == 'A' else 1\n",
    "        window_data = np.zeros((window_size, data.shape[1]))\n",
    "        window_data[:len(data), :] = data.iloc[:len(data)].to_numpy()\n",
    "        for i, (column, stats) in enumerate(extremes.items()):\n",
    "            if column in ['Signal A', 'Signal B', 'Signal C']:\n",
    "                window_data[:, i] = (window_data[:, i] - stats['min']) / (stats['max'] - stats['min'])\n",
    "            elif column == 'Time[s]':\n",
    "                window_data[:, i] = (window_data[:, i] - stats['mean']) / stats['std']\n",
    "            elif column in ['Sensor A', 'Sensor B', 'Sensor C', 'Sensor D']:\n",
    "                window_data[:, i] = (window_data[:, i] - stats['median']) / (stats['q3'] - stats['q1'])\n",
    "        sequences.append(window_data)\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c203f18-dfe9-430a-8082-f1143267b296",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e6c3361c6148dcb3abc75d7f41fd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_window_data = make_predict_data(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b2a7bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4048, 500, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_window_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec0a970-4d99-486d-b9b5-210f3cdca353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), self.Y[index]\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ace1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_size=9, num_layers=4, nhead=9, max_seq_length=500):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.nhead = nhead\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=self.hidden_size,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=self.hidden_size * 4,\n",
    "            dropout=0.1,\n",
    "            activation='relu'\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc_out = nn.Linear(self.hidden_size, 1)\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, max_seq_length, self.input_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, features = x.size()\n",
    "        pos_encoding = self.positional_encoding[:, :seq_length, :]\n",
    "        x = x + pos_encoding\n",
    "        x = x.permute(1, 0, 2)\n",
    "        transformer_out = self.transformer_encoder(x)\n",
    "        last_output = transformer_out[-1, :, :]\n",
    "        output = self.fc_out(last_output)\n",
    "        return output.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c7629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_window_data, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "214f30d4-2b19-479f-89b7-bf5bb2adc111",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = np.array([102, 200, 300, 402, 500, 602, 702, 802, 902])\n",
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X in tqdm(iter(test_loader)):\n",
    "            X = X.to(device)\n",
    "            output = model(X)\n",
    "            output = output * 902.\n",
    "            output = output.cpu().numpy()\n",
    "            predictions.extend(output)\n",
    "    return np.array(predictions)\n",
    "\n",
    "def map_predictions(predictions, target_values):\n",
    "    mapped_predictions = []\n",
    "    for pred in predictions:\n",
    "        differences = np.abs(target_values - pred)\n",
    "        index_of_min_diff = np.argmin(differences)\n",
    "        mapped_predictions.append(target_values[index_of_min_diff])\n",
    "    return np.array(mapped_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0a39a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9040c7d5f05437ab197d1f6bd5a1b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d46ad383504b068e92e85da3b0682a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918c11ec7efc48c18057b6dbc9f3d4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c7bfa4b75d495494a73395281a8177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1018858f01e43c38c3f9051720f07e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([191, 406, 639, ..., 476, 654, 401]),\n",
       " array([203, 430, 606, ..., 349, 620,  -5]),\n",
       " array([257, 354, 684, ..., 658, 602, 126]),\n",
       " array([ -3, 489, 595, ..., 722, 636,  15]),\n",
       " array([323, 389, 640, ..., 533, 689,  -2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model00 = TimeSeriesTransformer(input_size=9, num_layers=4, nhead=9, max_seq_length=500)\n",
    "model01 = TimeSeriesTransformer(input_size=9, num_layers=4, nhead=9, max_seq_length=500)\n",
    "model02 = TimeSeriesTransformer(input_size=9, num_layers=4, nhead=9, max_seq_length=500)\n",
    "model03 = TimeSeriesTransformer(input_size=9, num_layers=4, nhead=9, max_seq_length=500)\n",
    "model04 = TimeSeriesTransformer(input_size=9, num_layers=4, nhead=9, max_seq_length=500)\n",
    "\n",
    "model00 = torch.load('./fold/0_model_weights.pth')\n",
    "model01 = torch.load('./fold/1_model_weights.pth')\n",
    "model02 = torch.load('./fold/2_model_weights.pth')\n",
    "model03 = torch.load('./fold/3_model_weights.pth')\n",
    "model04 = torch.load('./fold/4_model_weights.pth')\n",
    "\n",
    "model00.to(device)\n",
    "model01.to(device)\n",
    "model02.to(device)\n",
    "model03.to(device)\n",
    "model04.to(device)\n",
    "\n",
    "pred00 = inference(model00, test_loader, device)\n",
    "pred01 = inference(model01, test_loader, device)\n",
    "pred02 = inference(model02, test_loader, device)\n",
    "pred03 = inference(model03, test_loader, device)\n",
    "pred04 = inference(model04, test_loader, device)\n",
    "\n",
    "pred00 = np.round(pred00, 0).astype(int)\n",
    "pred01 = np.round(pred01, 0).astype(int)\n",
    "pred02 = np.round(pred02, 0).astype(int)\n",
    "pred03 = np.round(pred03, 0).astype(int)\n",
    "pred04 = np.round(pred04, 0).astype(int)\n",
    "\n",
    "pred00, pred01, pred02, pred03, pred04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "126215dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([194, 414, 633, ..., 548, 640, 107])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictions_reproducibility = (pred00 + pred01 + pred02 + pred03 + pred04)/5\n",
    "Predictions_reproducibility = np.round(Predictions_reproducibility, 0).astype(int)\n",
    "Predictions_reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0eec7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200, 402, 602, ..., 500, 602, 102])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mapped_Predictions_Reproducibility = map_predictions(Predictions_reproducibility, target_values)\n",
    "Mapped_Predictions_Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c203cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['weight'] = Mapped_Predictions_Reproducibility\n",
    "submit.to_csv('./Mapped_Predictions_Reproducibility.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b457a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.14 (NGC 22.12/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
